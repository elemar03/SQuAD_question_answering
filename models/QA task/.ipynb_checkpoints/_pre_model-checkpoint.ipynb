{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `'../preprocessing/squad_preprocessing.ipynb.py'` not found.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_data_from_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-95a90385abcb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# Get the preprocessed data from the files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data_from_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mdev_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data_from_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dev\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_data_from_file' is not defined"
     ]
    }
   ],
   "source": [
    "%run ../../preprocessing/squad_preprocessing.ipynb\n",
    "\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Input, Dropout, Embedding, Flatten, Dense, Bidirectional, LSTM, GRU\n",
    "from keras.layers import RepeatVector, Activation, merge, Lambda, Flatten, Reshape, TimeDistributed\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D, GlobalAveragePooling1D\n",
    "from keras.layers import GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "#squad_preprocessing_main(contexts_max_len=1300, max_size=None)\n",
    "vocabulary_size = 103024\n",
    "\n",
    "# Get the preprocessed data from the files\n",
    "train_data = get_data_from_file(\"train\")\n",
    "dev_data = get_data_from_file(\"dev\")\n",
    "\n",
    "# Calculate the maximum length of the contexts and the questions\n",
    "assert max_len(train_data['contexts']) == max_len(dev_data['contexts'])\n",
    "assert max_len(train_data['questions']) == max_len(dev_data['questions'])\n",
    "c_maxlen =  max_len(train_data['contexts'])\n",
    "q_maxlen =  max_len(train_data['questions'])\n",
    "\n",
    "# Encode the labels\n",
    "train_data['start_wordloc'], train_data['end_wordloc'] = onehot_labels(train_data['start_wordloc'], train_data['end_wordloc'], c_maxlen)\n",
    "dev_data['start_wordloc'], dev_data['end_wordloc'] = onehot_labels(dev_data['start_wordloc'], dev_data['end_wordloc'], c_maxlen)\n",
    "print(train_data['contexts'].shape)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
