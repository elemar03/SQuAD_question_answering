{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** One-hot encoding the labels in two tensors . . .\n",
      "** One-hot encoding the labels in two tensors . . .\n",
      "(80377, 263)\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "%run ../../preprocessing/squad_preprocessing.ipynb\n",
    "\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Input, Dropout, Embedding, Flatten, Dense, Bidirectional, LSTM, GRU\n",
    "from keras.layers import RepeatVector, Activation, merge, Lambda, Flatten, Reshape, TimeDistributed\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D, GlobalAveragePooling1D\n",
    "from keras.layers import GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "#squad_preprocessing_main(contexts_max_len=1300, max_size=None)\n",
    "vocabulary_size = 103024\n",
    "\n",
    "# Get the preprocessed data from the files\n",
    "train_data = get_data_from_file(\"train\")\n",
    "dev_data = get_data_from_file(\"dev\")\n",
    "\n",
    "# Calculate the maximum length of the contexts and the questions\n",
    "assert max_len(train_data['contexts']) == max_len(dev_data['contexts'])\n",
    "assert max_len(train_data['questions']) == max_len(dev_data['questions'])\n",
    "c_maxlen =  max_len(train_data['contexts'])\n",
    "q_maxlen =  max_len(train_data['questions'])\n",
    "\n",
    "# Encode the labels\n",
    "train_data['start_wordloc'], train_data['end_wordloc'] = onehot_labels(train_data['start_wordloc'], train_data['end_wordloc'], c_maxlen)\n",
    "dev_data['start_wordloc'], dev_data['end_wordloc'] = onehot_labels(dev_data['start_wordloc'], dev_data['end_wordloc'], c_maxlen)\n",
    "print(train_data['contexts'].shape)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
